{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Hand-written Digit Recognition\n",
    "\n",
    "(a) Code a function that displays at least one image per each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "traindata = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.loc[:,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_to_plot = 10\n",
    "indices = target.drop_duplicates()\n",
    "\n",
    "sample_images = data.drop_duplicates('label').drop(\"label\", axis=1)\n",
    "sample_labels = target.drop_duplicates()\n",
    "\n",
    "plt.clf()\n",
    "plt.style.use('seaborn-muted')\n",
    "\n",
    "fig, axes = plt.subplots(5,2, \n",
    "                         figsize=(5,5),\n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "for i in range(images_to_plot):\n",
    "    \n",
    "    # axes (subplot) objects are stored in 2d array, accessed with axes[row,col]\n",
    "    subplot_row = i//2 \n",
    "    subplot_col = i%2\n",
    "    ax = axes[subplot_row, subplot_col]\n",
    "\n",
    "    # plot image on subplot\n",
    "    plottable_image = np.reshape(sample_images.iloc[i,:].values, (28,28))\n",
    "    ax.imshow(plottable_image, cmap='gray_r')\n",
    "    \n",
    "    ax.set_title('Digit Label: {}'.format(sample_labels.iloc[i]))\n",
    "    ax.set_xbound([0,28])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Measure the distribution over the labels in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x214495cd248>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution = target.value_counts(normalize=True)\n",
    "import seaborn\n",
    "seaborn.barplot(x=distribution.index, y=distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the distribution of digits in the training data is almost uniform so it is fit for modelling. Digit 1 has slightly more rows in the data compared to digit 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Implement a neural-net classifier with varying the number of hidden layers and neurons there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train test split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "sample_sub = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the features and labels and normalize them on scale of 0-1\n",
    "targets_np = train.label.values\n",
    "features_np = train.loc[:, train.columns != 'label'].values/255\n",
    "\n",
    "# Split into training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_np, targets_np, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and targets tensor for train set\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(target_train).type(torch.LongTensor)\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(target_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 256\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "    \n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33600, 784])\n",
      "torch.Size([8400, 784])\n"
     ]
    }
   ],
   "source": [
    "#Train-Test data distribution\n",
    "print(featuresTrain.shape)\n",
    "print(featuresTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 5 Hidden Layer Network\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Dropout module with 0.2 probbability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        # Add softmax on output layer\n",
    "        self.log_softmax = F.log_softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        \n",
    "        x = self.log_softmax(self.fc5(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 5 Hidden Layer Network\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Dropout module with 0.2 probbability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        # Add softmax on output layer\n",
    "        self.log_softmax = F.log_softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        x = self.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 5 Hidden Layer Network\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Dropout module with 0.2 probbability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        # Add softmax on output layer\n",
    "        self.log_softmax = F.log_softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        \n",
    "        x = self.log_softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25..  Training Loss: 0.438..  Test Loss: 0.432..  Test Accuracy: 0.870\n",
      "Epoch: 1/25..  Training Loss: 0.596..  Test Loss: 0.292..  Test Accuracy: 0.911\n",
      "Epoch: 2/25..  Training Loss: 0.035..  Test Loss: 0.202..  Test Accuracy: 0.941\n",
      "Epoch: 2/25..  Training Loss: 0.114..  Test Loss: 0.189..  Test Accuracy: 0.942\n",
      "Epoch: 2/25..  Training Loss: 0.186..  Test Loss: 0.149..  Test Accuracy: 0.954\n",
      "Epoch: 3/25..  Training Loss: 0.043..  Test Loss: 0.147..  Test Accuracy: 0.957\n",
      "Epoch: 3/25..  Training Loss: 0.099..  Test Loss: 0.133..  Test Accuracy: 0.958\n",
      "Epoch: 4/25..  Training Loss: 0.006..  Test Loss: 0.136..  Test Accuracy: 0.959\n",
      "Epoch: 4/25..  Training Loss: 0.048..  Test Loss: 0.114..  Test Accuracy: 0.966\n",
      "Epoch: 4/25..  Training Loss: 0.092..  Test Loss: 0.105..  Test Accuracy: 0.968\n",
      "Epoch: 5/25..  Training Loss: 0.013..  Test Loss: 0.111..  Test Accuracy: 0.969\n",
      "Epoch: 5/25..  Training Loss: 0.044..  Test Loss: 0.126..  Test Accuracy: 0.961\n",
      "Epoch: 5/25..  Training Loss: 0.080..  Test Loss: 0.106..  Test Accuracy: 0.969\n",
      "Epoch: 6/25..  Training Loss: 0.023..  Test Loss: 0.100..  Test Accuracy: 0.971\n",
      "Epoch: 6/25..  Training Loss: 0.050..  Test Loss: 0.100..  Test Accuracy: 0.972\n",
      "Epoch: 7/25..  Training Loss: 0.004..  Test Loss: 0.113..  Test Accuracy: 0.968\n",
      "Epoch: 7/25..  Training Loss: 0.032..  Test Loss: 0.091..  Test Accuracy: 0.974\n",
      "Epoch: 7/25..  Training Loss: 0.056..  Test Loss: 0.092..  Test Accuracy: 0.974\n",
      "Epoch: 8/25..  Training Loss: 0.011..  Test Loss: 0.096..  Test Accuracy: 0.974\n",
      "Epoch: 8/25..  Training Loss: 0.031..  Test Loss: 0.100..  Test Accuracy: 0.972\n",
      "Epoch: 8/25..  Training Loss: 0.053..  Test Loss: 0.109..  Test Accuracy: 0.971\n",
      "Epoch: 9/25..  Training Loss: 0.018..  Test Loss: 0.110..  Test Accuracy: 0.971\n",
      "Epoch: 9/25..  Training Loss: 0.037..  Test Loss: 0.103..  Test Accuracy: 0.973\n",
      "Epoch: 10/25..  Training Loss: 0.004..  Test Loss: 0.094..  Test Accuracy: 0.975\n",
      "Epoch: 10/25..  Training Loss: 0.020..  Test Loss: 0.094..  Test Accuracy: 0.974\n",
      "Epoch: 10/25..  Training Loss: 0.039..  Test Loss: 0.097..  Test Accuracy: 0.975\n",
      "Epoch: 11/25..  Training Loss: 0.009..  Test Loss: 0.094..  Test Accuracy: 0.975\n",
      "Epoch: 11/25..  Training Loss: 0.023..  Test Loss: 0.115..  Test Accuracy: 0.973\n",
      "Epoch: 11/25..  Training Loss: 0.040..  Test Loss: 0.095..  Test Accuracy: 0.976\n",
      "Epoch: 12/25..  Training Loss: 0.013..  Test Loss: 0.105..  Test Accuracy: 0.976\n",
      "Epoch: 12/25..  Training Loss: 0.027..  Test Loss: 0.103..  Test Accuracy: 0.976\n",
      "Epoch: 13/25..  Training Loss: 0.004..  Test Loss: 0.098..  Test Accuracy: 0.977\n",
      "Epoch: 13/25..  Training Loss: 0.015..  Test Loss: 0.101..  Test Accuracy: 0.976\n",
      "Epoch: 13/25..  Training Loss: 0.030..  Test Loss: 0.104..  Test Accuracy: 0.972\n",
      "Epoch: 14/25..  Training Loss: 0.011..  Test Loss: 0.095..  Test Accuracy: 0.975\n",
      "Epoch: 14/25..  Training Loss: 0.025..  Test Loss: 0.095..  Test Accuracy: 0.976\n",
      "Epoch: 15/25..  Training Loss: 0.001..  Test Loss: 0.103..  Test Accuracy: 0.976\n",
      "Epoch: 15/25..  Training Loss: 0.011..  Test Loss: 0.109..  Test Accuracy: 0.974\n",
      "Epoch: 15/25..  Training Loss: 0.024..  Test Loss: 0.108..  Test Accuracy: 0.976\n",
      "Epoch: 16/25..  Training Loss: 0.004..  Test Loss: 0.101..  Test Accuracy: 0.977\n",
      "Epoch: 16/25..  Training Loss: 0.013..  Test Loss: 0.112..  Test Accuracy: 0.975\n",
      "Epoch: 16/25..  Training Loss: 0.024..  Test Loss: 0.099..  Test Accuracy: 0.978\n",
      "Epoch: 17/25..  Training Loss: 0.006..  Test Loss: 0.112..  Test Accuracy: 0.977\n",
      "Epoch: 17/25..  Training Loss: 0.016..  Test Loss: 0.114..  Test Accuracy: 0.976\n",
      "Epoch: 18/25..  Training Loss: 0.003..  Test Loss: 0.121..  Test Accuracy: 0.971\n",
      "Epoch: 18/25..  Training Loss: 0.017..  Test Loss: 0.098..  Test Accuracy: 0.976\n",
      "Epoch: 18/25..  Training Loss: 0.026..  Test Loss: 0.101..  Test Accuracy: 0.977\n",
      "Epoch: 19/25..  Training Loss: 0.005..  Test Loss: 0.103..  Test Accuracy: 0.976\n",
      "Epoch: 19/25..  Training Loss: 0.012..  Test Loss: 0.110..  Test Accuracy: 0.977\n",
      "Epoch: 19/25..  Training Loss: 0.022..  Test Loss: 0.105..  Test Accuracy: 0.976\n",
      "Epoch: 20/25..  Training Loss: 0.007..  Test Loss: 0.105..  Test Accuracy: 0.977\n",
      "Epoch: 20/25..  Training Loss: 0.013..  Test Loss: 0.112..  Test Accuracy: 0.977\n",
      "Epoch: 21/25..  Training Loss: 0.001..  Test Loss: 0.101..  Test Accuracy: 0.976\n",
      "Epoch: 21/25..  Training Loss: 0.008..  Test Loss: 0.111..  Test Accuracy: 0.977\n",
      "Epoch: 21/25..  Training Loss: 0.016..  Test Loss: 0.103..  Test Accuracy: 0.979\n",
      "Epoch: 22/25..  Training Loss: 0.004..  Test Loss: 0.114..  Test Accuracy: 0.978\n",
      "Epoch: 22/25..  Training Loss: 0.013..  Test Loss: 0.113..  Test Accuracy: 0.977\n",
      "Epoch: 22/25..  Training Loss: 0.019..  Test Loss: 0.106..  Test Accuracy: 0.980\n",
      "Epoch: 23/25..  Training Loss: 0.008..  Test Loss: 0.117..  Test Accuracy: 0.976\n",
      "Epoch: 23/25..  Training Loss: 0.014..  Test Loss: 0.114..  Test Accuracy: 0.977\n",
      "Epoch: 24/25..  Training Loss: 0.003..  Test Loss: 0.112..  Test Accuracy: 0.977\n",
      "Epoch: 24/25..  Training Loss: 0.009..  Test Loss: 0.101..  Test Accuracy: 0.979\n",
      "Epoch: 24/25..  Training Loss: 0.016..  Test Loss: 0.111..  Test Accuracy: 0.979\n",
      "Epoch: 25/25..  Training Loss: 0.004..  Test Loss: 0.113..  Test Accuracy: 0.978\n",
      "Epoch: 25/25..  Training Loss: 0.009..  Test Loss: 0.130..  Test Accuracy: 0.976\n",
      "Epoch: 25/25..  Training Loss: 0.017..  Test Loss: 0.108..  Test Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model 1\n",
    "model = Classifier1()\n",
    "# Define our loss function\n",
    "criterion = nn.NLLLoss()\n",
    "# Define the optimier\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0015)\n",
    "\n",
    "epochs = 25\n",
    "steps = 0\n",
    "print_every = 50\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        steps += 1\n",
    "        # Prevent accumulation of gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Make predictions\n",
    "        log_ps = model(images.float())\n",
    "        loss = criterion(log_ps, labels)\n",
    "        #backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Turn off gradients for validation\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for images, labels in test_loader:\n",
    "                    log_ps = model(images.float())\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    # Get our top predictions\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25..  Training Loss: 0.373..  Test Loss: 0.358..  Test Accuracy: 0.888\n",
      "Epoch: 1/25..  Training Loss: 0.508..  Test Loss: 0.238..  Test Accuracy: 0.926\n",
      "Epoch: 2/25..  Training Loss: 0.029..  Test Loss: 0.192..  Test Accuracy: 0.942\n",
      "Epoch: 2/25..  Training Loss: 0.106..  Test Loss: 0.167..  Test Accuracy: 0.949\n",
      "Epoch: 2/25..  Training Loss: 0.169..  Test Loss: 0.146..  Test Accuracy: 0.955\n",
      "Epoch: 3/25..  Training Loss: 0.037..  Test Loss: 0.133..  Test Accuracy: 0.959\n",
      "Epoch: 3/25..  Training Loss: 0.088..  Test Loss: 0.136..  Test Accuracy: 0.960\n",
      "Epoch: 4/25..  Training Loss: 0.003..  Test Loss: 0.123..  Test Accuracy: 0.964\n",
      "Epoch: 4/25..  Training Loss: 0.039..  Test Loss: 0.108..  Test Accuracy: 0.967\n",
      "Epoch: 4/25..  Training Loss: 0.076..  Test Loss: 0.103..  Test Accuracy: 0.968\n",
      "Epoch: 5/25..  Training Loss: 0.014..  Test Loss: 0.096..  Test Accuracy: 0.970\n",
      "Epoch: 5/25..  Training Loss: 0.042..  Test Loss: 0.099..  Test Accuracy: 0.969\n",
      "Epoch: 5/25..  Training Loss: 0.072..  Test Loss: 0.099..  Test Accuracy: 0.971\n",
      "Epoch: 6/25..  Training Loss: 0.021..  Test Loss: 0.097..  Test Accuracy: 0.972\n",
      "Epoch: 6/25..  Training Loss: 0.049..  Test Loss: 0.088..  Test Accuracy: 0.973\n",
      "Epoch: 7/25..  Training Loss: 0.004..  Test Loss: 0.096..  Test Accuracy: 0.972\n",
      "Epoch: 7/25..  Training Loss: 0.023..  Test Loss: 0.087..  Test Accuracy: 0.974\n",
      "Epoch: 7/25..  Training Loss: 0.046..  Test Loss: 0.084..  Test Accuracy: 0.976\n",
      "Epoch: 8/25..  Training Loss: 0.008..  Test Loss: 0.087..  Test Accuracy: 0.976\n",
      "Epoch: 8/25..  Training Loss: 0.027..  Test Loss: 0.097..  Test Accuracy: 0.972\n",
      "Epoch: 8/25..  Training Loss: 0.047..  Test Loss: 0.081..  Test Accuracy: 0.975\n",
      "Epoch: 9/25..  Training Loss: 0.014..  Test Loss: 0.090..  Test Accuracy: 0.974\n",
      "Epoch: 9/25..  Training Loss: 0.028..  Test Loss: 0.084..  Test Accuracy: 0.977\n",
      "Epoch: 10/25..  Training Loss: 0.003..  Test Loss: 0.090..  Test Accuracy: 0.974\n",
      "Epoch: 10/25..  Training Loss: 0.016..  Test Loss: 0.086..  Test Accuracy: 0.976\n",
      "Epoch: 10/25..  Training Loss: 0.029..  Test Loss: 0.081..  Test Accuracy: 0.976\n",
      "Epoch: 11/25..  Training Loss: 0.007..  Test Loss: 0.092..  Test Accuracy: 0.974\n",
      "Epoch: 11/25..  Training Loss: 0.023..  Test Loss: 0.087..  Test Accuracy: 0.976\n",
      "Epoch: 11/25..  Training Loss: 0.034..  Test Loss: 0.092..  Test Accuracy: 0.974\n",
      "Epoch: 12/25..  Training Loss: 0.012..  Test Loss: 0.094..  Test Accuracy: 0.975\n",
      "Epoch: 12/25..  Training Loss: 0.026..  Test Loss: 0.114..  Test Accuracy: 0.971\n",
      "Epoch: 13/25..  Training Loss: 0.004..  Test Loss: 0.088..  Test Accuracy: 0.975\n",
      "Epoch: 13/25..  Training Loss: 0.015..  Test Loss: 0.086..  Test Accuracy: 0.978\n",
      "Epoch: 13/25..  Training Loss: 0.026..  Test Loss: 0.108..  Test Accuracy: 0.974\n",
      "Epoch: 14/25..  Training Loss: 0.007..  Test Loss: 0.090..  Test Accuracy: 0.977\n",
      "Epoch: 14/25..  Training Loss: 0.017..  Test Loss: 0.084..  Test Accuracy: 0.978\n",
      "Epoch: 15/25..  Training Loss: 0.000..  Test Loss: 0.084..  Test Accuracy: 0.978\n",
      "Epoch: 15/25..  Training Loss: 0.008..  Test Loss: 0.091..  Test Accuracy: 0.977\n",
      "Epoch: 15/25..  Training Loss: 0.017..  Test Loss: 0.094..  Test Accuracy: 0.978\n",
      "Epoch: 16/25..  Training Loss: 0.003..  Test Loss: 0.097..  Test Accuracy: 0.977\n",
      "Epoch: 16/25..  Training Loss: 0.012..  Test Loss: 0.092..  Test Accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model 2\n",
    "model = Classifier2()\n",
    "# Define our loss function\n",
    "criterion = nn.NLLLoss()\n",
    "# Define the optimier\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0015)\n",
    "\n",
    "epochs = 25\n",
    "steps = 0\n",
    "print_every = 50\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        steps += 1\n",
    "        # Prevent accumulation of gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Make predictions\n",
    "        log_ps = model(images.float())\n",
    "        loss = criterion(log_ps, labels)\n",
    "        #backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Turn off gradients for validation\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for images, labels in test_loader:\n",
    "                    log_ps = model(images.float())\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    # Get our top predictions\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25..  Training Loss: 0.327..  Test Loss: 0.355..  Test Accuracy: 0.896\n",
      "Epoch: 1/25..  Training Loss: 0.460..  Test Loss: 0.253..  Test Accuracy: 0.925\n",
      "Epoch: 2/25..  Training Loss: 0.033..  Test Loss: 0.213..  Test Accuracy: 0.937\n",
      "Epoch: 2/25..  Training Loss: 0.118..  Test Loss: 0.189..  Test Accuracy: 0.945\n",
      "Epoch: 2/25..  Training Loss: 0.187..  Test Loss: 0.156..  Test Accuracy: 0.954\n",
      "Epoch: 3/25..  Training Loss: 0.044..  Test Loss: 0.144..  Test Accuracy: 0.958\n",
      "Epoch: 3/25..  Training Loss: 0.101..  Test Loss: 0.134..  Test Accuracy: 0.960\n",
      "Epoch: 4/25..  Training Loss: 0.004..  Test Loss: 0.123..  Test Accuracy: 0.963\n",
      "Epoch: 4/25..  Training Loss: 0.045..  Test Loss: 0.118..  Test Accuracy: 0.964\n",
      "Epoch: 4/25..  Training Loss: 0.088..  Test Loss: 0.114..  Test Accuracy: 0.965\n",
      "Epoch: 5/25..  Training Loss: 0.016..  Test Loss: 0.107..  Test Accuracy: 0.968\n",
      "Epoch: 5/25..  Training Loss: 0.051..  Test Loss: 0.098..  Test Accuracy: 0.969\n",
      "Epoch: 5/25..  Training Loss: 0.085..  Test Loss: 0.093..  Test Accuracy: 0.971\n",
      "Epoch: 6/25..  Training Loss: 0.019..  Test Loss: 0.099..  Test Accuracy: 0.970\n",
      "Epoch: 6/25..  Training Loss: 0.049..  Test Loss: 0.090..  Test Accuracy: 0.973\n",
      "Epoch: 7/25..  Training Loss: 0.004..  Test Loss: 0.086..  Test Accuracy: 0.973\n",
      "Epoch: 7/25..  Training Loss: 0.026..  Test Loss: 0.089..  Test Accuracy: 0.972\n",
      "Epoch: 7/25..  Training Loss: 0.051..  Test Loss: 0.088..  Test Accuracy: 0.973\n",
      "Epoch: 8/25..  Training Loss: 0.010..  Test Loss: 0.084..  Test Accuracy: 0.974\n",
      "Epoch: 8/25..  Training Loss: 0.029..  Test Loss: 0.081..  Test Accuracy: 0.975\n",
      "Epoch: 8/25..  Training Loss: 0.049..  Test Loss: 0.081..  Test Accuracy: 0.976\n",
      "Epoch: 9/25..  Training Loss: 0.015..  Test Loss: 0.082..  Test Accuracy: 0.976\n",
      "Epoch: 9/25..  Training Loss: 0.033..  Test Loss: 0.078..  Test Accuracy: 0.977\n",
      "Epoch: 10/25..  Training Loss: 0.003..  Test Loss: 0.082..  Test Accuracy: 0.976\n",
      "Epoch: 10/25..  Training Loss: 0.015..  Test Loss: 0.078..  Test Accuracy: 0.977\n",
      "Epoch: 10/25..  Training Loss: 0.031..  Test Loss: 0.084..  Test Accuracy: 0.975\n",
      "Epoch: 11/25..  Training Loss: 0.007..  Test Loss: 0.078..  Test Accuracy: 0.977\n",
      "Epoch: 11/25..  Training Loss: 0.017..  Test Loss: 0.080..  Test Accuracy: 0.977\n",
      "Epoch: 11/25..  Training Loss: 0.031..  Test Loss: 0.091..  Test Accuracy: 0.975\n",
      "Epoch: 12/25..  Training Loss: 0.010..  Test Loss: 0.075..  Test Accuracy: 0.977\n",
      "Epoch: 12/25..  Training Loss: 0.021..  Test Loss: 0.090..  Test Accuracy: 0.975\n",
      "Epoch: 13/25..  Training Loss: 0.003..  Test Loss: 0.085..  Test Accuracy: 0.976\n",
      "Epoch: 13/25..  Training Loss: 0.014..  Test Loss: 0.080..  Test Accuracy: 0.977\n",
      "Epoch: 13/25..  Training Loss: 0.025..  Test Loss: 0.088..  Test Accuracy: 0.976\n",
      "Epoch: 14/25..  Training Loss: 0.007..  Test Loss: 0.083..  Test Accuracy: 0.978\n",
      "Epoch: 14/25..  Training Loss: 0.015..  Test Loss: 0.084..  Test Accuracy: 0.978\n",
      "Epoch: 15/25..  Training Loss: 0.000..  Test Loss: 0.097..  Test Accuracy: 0.975\n",
      "Epoch: 15/25..  Training Loss: 0.010..  Test Loss: 0.088..  Test Accuracy: 0.976\n",
      "Epoch: 15/25..  Training Loss: 0.019..  Test Loss: 0.089..  Test Accuracy: 0.976\n",
      "Epoch: 16/25..  Training Loss: 0.002..  Test Loss: 0.088..  Test Accuracy: 0.979\n",
      "Epoch: 16/25..  Training Loss: 0.010..  Test Loss: 0.088..  Test Accuracy: 0.978\n",
      "Epoch: 16/25..  Training Loss: 0.019..  Test Loss: 0.089..  Test Accuracy: 0.978\n",
      "Epoch: 17/25..  Training Loss: 0.005..  Test Loss: 0.085..  Test Accuracy: 0.979\n",
      "Epoch: 17/25..  Training Loss: 0.012..  Test Loss: 0.090..  Test Accuracy: 0.976\n",
      "Epoch: 18/25..  Training Loss: 0.001..  Test Loss: 0.089..  Test Accuracy: 0.979\n",
      "Epoch: 18/25..  Training Loss: 0.006..  Test Loss: 0.091..  Test Accuracy: 0.977\n",
      "Epoch: 18/25..  Training Loss: 0.013..  Test Loss: 0.091..  Test Accuracy: 0.979\n",
      "Epoch: 19/25..  Training Loss: 0.003..  Test Loss: 0.088..  Test Accuracy: 0.978\n",
      "Epoch: 19/25..  Training Loss: 0.010..  Test Loss: 0.090..  Test Accuracy: 0.977\n",
      "Epoch: 19/25..  Training Loss: 0.017..  Test Loss: 0.094..  Test Accuracy: 0.978\n",
      "Epoch: 20/25..  Training Loss: 0.005..  Test Loss: 0.087..  Test Accuracy: 0.980\n",
      "Epoch: 20/25..  Training Loss: 0.011..  Test Loss: 0.096..  Test Accuracy: 0.978\n",
      "Epoch: 21/25..  Training Loss: 0.002..  Test Loss: 0.098..  Test Accuracy: 0.977\n",
      "Epoch: 21/25..  Training Loss: 0.007..  Test Loss: 0.090..  Test Accuracy: 0.979\n",
      "Epoch: 21/25..  Training Loss: 0.012..  Test Loss: 0.100..  Test Accuracy: 0.978\n",
      "Epoch: 22/25..  Training Loss: 0.004..  Test Loss: 0.100..  Test Accuracy: 0.977\n",
      "Epoch: 22/25..  Training Loss: 0.009..  Test Loss: 0.090..  Test Accuracy: 0.979\n",
      "Epoch: 22/25..  Training Loss: 0.015..  Test Loss: 0.091..  Test Accuracy: 0.978\n",
      "Epoch: 23/25..  Training Loss: 0.004..  Test Loss: 0.094..  Test Accuracy: 0.979\n",
      "Epoch: 23/25..  Training Loss: 0.010..  Test Loss: 0.092..  Test Accuracy: 0.978\n",
      "Epoch: 24/25..  Training Loss: 0.002..  Test Loss: 0.102..  Test Accuracy: 0.976\n",
      "Epoch: 24/25..  Training Loss: 0.006..  Test Loss: 0.100..  Test Accuracy: 0.978\n",
      "Epoch: 24/25..  Training Loss: 0.011..  Test Loss: 0.099..  Test Accuracy: 0.977\n",
      "Epoch: 25/25..  Training Loss: 0.004..  Test Loss: 0.093..  Test Accuracy: 0.978\n",
      "Epoch: 25/25..  Training Loss: 0.009..  Test Loss: 0.097..  Test Accuracy: 0.979\n",
      "Epoch: 25/25..  Training Loss: 0.013..  Test Loss: 0.099..  Test Accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model 3\n",
    "model = Classifier3()\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.NLLLoss()\n",
    "# Define the optimier\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0015)\n",
    "\n",
    "epochs = 25\n",
    "steps = 0\n",
    "print_every = 50\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        steps += 1\n",
    "        # Prevent accumulation of gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Make predictions\n",
    "        log_ps = model(images.float())\n",
    "        loss = criterion(log_ps, labels)\n",
    "        #backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Turn off gradients for validation\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for images, labels in test_loader:\n",
    "                    log_ps = model(images.float())\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    # Get our top predictions\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                    \n",
    "            # Confusion matrix\n",
    "            #conf_mat=tf.math.confusion_matrix(top_class.numpy(),labels.numpy())\n",
    "            #confusion_matrix[top_class.numpy(),labels.numpy()] += 1\n",
    "            #print(conf_mat)\n",
    "            #        _, preds = torch.max(log_ps, 1)\n",
    "            #        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "            #            confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "             #       print(confusion_matrix)\n",
    "        \n",
    "            model.train()\n",
    "\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the best performing neural networks are models 2 and 3 with accuracy 97.9% each. However, we'll choose model 3 since it has only 1 hidden layer with 512 neurons which makes the training and testing computation less compared to model 2 with 2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[802   0   1   0   0   4   5   1   1   2]\n",
      " [  0 899   3   1   1   1   1   1   2   0]\n",
      " [  1   2 821   5   8   0   0   4   3   2]\n",
      " [  1   1   3 902   0  11   0   1   8  10]\n",
      " [  1   0   0   0 819   1   4   1   0  13]\n",
      " [  0   0   0   4   1 687   3   1   1   5]\n",
      " [  2   0   0   0   0   6 777   0   0   0]\n",
      " [  0   1   6   2   2   1   0 868   1  12]\n",
      " [  0   3   4   4   3   6   1   1 810   3]\n",
      " [  1   0   0   2   5   0   0   4   1 825]]\n",
      "F1 score: 0.977381\n",
      "Accuracy score: 0.977381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test_label_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            #data, target = data.to(device), target.to(device)\n",
    "            output = model(data.float())\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            actuals.extend(target.view_as(prediction))\n",
    "            predictions.extend(prediction)\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "\n",
    "actuals, predictions = test_label_predictions(model, test_loader)\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(actuals, predictions))\n",
    "print('F1 score: %f' % f1_score(actuals, predictions, average='micro'))\n",
    "print('Accuracy score: %f' % accuracy_score(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Accuracy of digit 0 is 0.9828431372549019\n",
      "Class Accuracy of digit 1 is 0.988998899889989\n",
      "Class Accuracy of digit 2 is 0.9704491725768322\n",
      "Class Accuracy of digit 3 is 0.9626467449306296\n",
      "Class Accuracy of digit 4 is 0.9761620977353993\n",
      "Class Accuracy of digit 5 is 0.9786324786324786\n",
      "Class Accuracy of digit 6 is 0.9898089171974522\n",
      "Class Accuracy of digit 7 is 0.9720044792833147\n",
      "Class Accuracy of digit 8 is 0.9700598802395209\n",
      "Class Accuracy of digit 9 is 0.9844868735083532\n"
     ]
    }
   ],
   "source": [
    "confmat=confusion_matrix(actuals, predictions)\n",
    "classacc=list(range(0, 10))\n",
    "for i in range(0,10):\n",
    "    classacc[i] = confmat[i,i]/sum(confmat[i,:])\n",
    "    print(f'Class Accuracy of digit {i} is {classacc[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that digit 3 has the least accuracy with 96.26% where it was misclassified as digit 5 and 9 for 11 and 10 times respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digit 6 has the best accuracy with 98.98% out of all digits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
